%%
% 引言或背景
% 引言是论文正文的开端,应包括毕业论文选题的背景、目的和意义;对国内外研究现状和相关领域中已有的研究成果的简要评述;介绍本项研究工作研究设想、研究方法或实验设计、理论依据或实验基础;涉及范围和预期结果等。要求言简意赅,注意不要与摘要雷同或成为摘要的注解。
% modifier: 黄俊杰(huangjj27, 349373001dc@gmail.com)
% update date: 2017-04-15
%%

\chapter{绪论}
%定义，过去的研究和现在的研究，意义，与图像分割的不同,going deeper
\section{选题背景与意义}
\label{sec:background}
% What is the problem
% why is it interesting and important
% Why is it hards, why do naive approaches fails
% why hasn't it been solved before
% what are the key components of my approach and results, also include any specific limitations，do not repeat the abstract
%contribution
\label{sec:intro}

近年来，随着诸如SDXL~\cite{SDXL}、DALL-E 3~\cite{DALLE_2}以及DeepFloyd~\cite{SDXL, DALLE_2, shonenkov2023deepfloyd}等文本到图像扩散模型的快速发展，它们在生成高保真度图像领域取得了显著的进步。此类模型凭借大规模的预训练数据集，展现出对于各类物体图像的有效生成能力。然而，在构建具有复杂灵活结构的图像，尤其是人体图像时，现有的文本到图像模型面临重大挑战。如图~\ref{fig:intro}所示，典型问题包括不恰当的肢体数量或异常的肢体细节表现，例如不规则的手指排列。这些问题源于模型在预训练阶段往往注重捕捉整体特征（如人体具备四肢的基本结构），而对局部细节特征（如手指的确切数目）的关注不足，从而导致模型在精确控制细微身体部位生成时表现出局限性，欠缺辨别正常与异常人体特征的知识体系。

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{fig/intro.pdf}
    \caption{利用最先进的文本到图像扩散模型SDXL~\cite{SDXL}合成的人像图像仍存在错误的肢体数量、扭曲的手部和不正确的肢体位置问题。本文提出了\textit{HumanRefiner}，这是一个建立在\textit{AbHuman}基准上的粗到细的自我诊断姿势/异常可逆生成流水线，旨在消除这些异常。}
    \label{fig:intro}
\end{figure}


尽管已有一些工作，如HumanSD~\cite{ju2023humansd}、Pose-ControlNet~\cite{controlnet} 和 T2I-Adapter~\cite{t2i_adapter}，尝试通过引入附加姿态信息来改善模型在此方面的性能，但由于这些方法依赖于额外的输入条件，其实际应用及泛化能力受到限制，难以广泛适用于各类文本到图像生成任务。

因此，本文旨在提升文本到图像扩散模型对人类解剖学异常的理解，并运用这种理解来驱动模型生成更为准确真实的人体图像。为了解决上述难题，本文构建了首个专门针对人类解剖异常的大规模合成数据集——\textbf{AbHuman}。此基准集包含56,000幅细致标注的合成人类图像，共记录了147,000例详尽的肢体异常实例，其中每一个异常均在边界框级别进行了精准标注。另外，异常情况并未简单划分为单一的“异常身体”类别，而是细分为18个不同的子类别，涵盖“异常/正常头部”、“异常/正常手部”、“异常/正常足部”等多种类型。

借助AbHuman基准集中丰富的异常注释信息，本文能够直接汲取关于人类异常状态的知识，并通过传统负向提示技术将其融入扩散模型中。此外，一种替代策略是开发一款异常评分器，该评分器能对生成图像提供反馈，以区分正常和异常图像，并对生成图像中的异常情况进行量化评估，进而指导文本到图像扩散过程。

然而，仅采用传统的基于AbHuman基准集的异常标题信息并未充分利用其中详尽的边界框级别注解。因此，本文提出了一种创新且适应性强的方法——\textbf{HumanRefiner}，该方法可无缝集成至任何文本到图像生成模型中，专用于解决人类解剖异常问题。HumanRefiner超越了简单的异常导向和负向提示技术，通过实现一种从粗略到精细、姿态可逆的扩散生成流程，包括全局姿态引导修正以及基于异常检测器引导的局部精细修复。具体而言，使用在AbHuman上训练的异常检测器来精确识别并处理细粒度异常。

在AbHuman基准上的实验证明，HumanRefiner显著减少了生成图像中的不一致性问题，相较于领先开源生成器SDXL，在肢体质量方面实现了2.9倍的性能提升；同时，在人工评价环节中，相对于DALL-E 3也获得了1.4倍的偏好度提高。综上所述，本文的主要贡献概括如下：
\begin{itemize}
\item 构建了AbHuman，这是首个包含56,000幅带有详尽边界框级别人类异常标签的大规模合成解剖异常基准数据集。
\item 提出HumanRefiner，作为一种创新且即插即用的方法，通过姿态可逆引导机制实现对人体异常的由粗至精修正。
\item 完备的实验结果显示，与最先进的文本到图像模型相比，HumanRefiner明显减少了生成图像的差异性。尤其在人体图像质量的主观评价中，HumanRefiner相较于SDXL提升了2.9倍的生成效果偏好度，相比于DALL-E 3则提高了1.4倍。
\end{itemize}

\section{国内外研究现状和相关工作}
\label{sec:related_work}
\subsection{文本到图像/人类生成}

\textbf{文本到图像生成。}近年来，文本到图像合成的研究致力于根据自然语言描述创建高质量的图像，已取得显著进展。这一领域的快速发展受益于大规模图像-文本数据集\cite{kakaobrain2022coyo_700m, schuhmann2022laion}、多种先进的训练与推断技术\cite{NEURIPS2020_4c5bcfec, song2020denoising, ho2022cascaded}以及模型可扩展性方面的增强\cite{DALLE_2}。目前，文本到图像模型主要可分为三大类：扩散模型\cite{balaji2022ediffi, DALLE_2, GLIDE, saharia2022photorealistic, gafni2022make, stablediffusion, Imagen_saharia2022photorealistic}、自回归模型\cite{ramesh2021zero, yu2022scaling, chang2023muse}以及生成对抗网络模型\cite{sauer2023stylegan, kang2023scaling, zhang2022exploringGAN}。近期发布的DALL-E 3\cite{openai2023dalle3}和SDXL\cite{SDXL}等最新模型，在图像生成质量上展现出重大提升。

尽管如此，由文本生成逼真人体图像的任务仍然具有相当难度，原因在于人体姿态的多样性和图像与文本间精准对应关系的缺失。尤其是，现存模型大多缺乏对人体结构内在规则的内建理解，导致其在生成具有合理解剖学特征的人像时困难重重，比如正确再现人物应有的四肢数量。

为此，本文工作的核心聚焦于提高基于文本生成的人体图像质量。近年来，扩散型文本到图像模型因具备卓越的可扩展性和稳定的训练性能，已在表现力上超越了传统的生成对抗网络\cite{dhariwal2021diffusion}，成为图像生成领域的主要选择\cite{nichol2021glide, saharia2022photorealistic, balaji2022ediffi, li2023snapfusion}。这类模型通过将生成过程形式化为迭代去噪过程\cite{ho2020denoising}，诸如Stable Diffusion\cite{Rombach_2022_CVPR}和DALL·E 2\cite{ramesh2022hierarchical}等典型工作展示了前所未有的图像生成品质。然而，针对高保真度人体图像生成的局限，本文所提出的方案是在扩散模型的潜在空间中明确定义和建模人体结构，从而针对性地解决这一问题。

\textbf{可控人类图像生成的研究进展与新路径探索。}当前对于可控人类图像生成的研究领域中，众多模型不断努力以提升真实人类图像的质量。这些研究表明，在扩散模型中嵌入附加条件有利于对人类图像生成提供更为精确的导向。例如，文献\cite{controlnet, t2i_adapter, huang2023composer}所介绍的模型通过引入额外的训练模块实现了人体姿态条件的融入，进而能够精细化调控生成的人类图像。同时，文献\cite{li2023gligen}不仅考虑了关键点信息，还整合了边界框检测数据，增强了姿态引导的细致程度。在此基础上，文献\cite{ju2023humansd}采用了一种热图对齐策略，进一步提升了生成高质量人类图像的能力。

尽管已有研究取得了显著成果，但现有的面向人类生成任务仍面临着两大核心难题：（1）引入的姿态条件虽有助于生成，但也明显制约了人体姿态的多样表达性；（2）仅仅依赖姿态条件难以充分解决人体各部位如手部、脚部及面部特征等的细粒度细节生成问题。

不同于既有研究方向，本研究提出“HumanRefiner”方法，旨在在不依赖人工提供的姿态条件的前提下，解决人类图像生成中的上述问题。传统可控人类图像生成方法可大致划分为基于GANs的\cite{zhu2017your, siarohin2019appearance}和基于VAEs的\cite{ren2020deep, yang2021towards}两类，它们通常接受参考图像和各种条件作为输入。为了便于用户友好应用，近期一些研究尝试利用文本提示作为生成指导手段\cite{roy2022tips, jiang2022text2human}，但往往局限于简单姿态或风格描述。与此最相关的一些工作，如ControlNet\cite{zhang2023adding}、T2I-Adapter\cite{mou2023t2i}以及HumanSD\cite{ju2023humansd}，虽然开启了开放词汇引导的可控姿态人类合成研究，但要么存在姿势控制不足的问题，要么仅限于有限艺术风格多样性。此外，多数前期研究仅关注姿态输入，而忽略了人体外观与其不同层次结构信息间的多级关联性。

鉴于此，本工作中，本文提出由粗到细多步骤重绘的方法，从粗略的姿态层级直至细粒度的肢体结构，逐步整合结构意识，旨在在一个统一框架中同时捕捉显式的外观信息和潜在的结构信息，从而实现逼真人类图像的综合生成。通过这种方法，本文旨在突破现有方法的局限，开辟一条兼顾多样性和细节控制的新路径。

\subsection{人类图像生成的数据集现状}

当前人类图像生成领域的数据集主要涵盖两大类别。首类数据集集中于对自然环境下个体真实形态的记录，这包括来源于人类照片和视频数据的图像\cite{MSCOCO_lin2014microsoft, schuhmann2022laion, Pose2Seg_zhang2019pose2seg, HandDetec_narasimhaswamy2022whose, CrowdPose_li2019crowdpose, Posetrack_andriluka2018posetrack, Yutubepose_charles2016personalizing, open_pose_cao2017realtime}。这类广泛使用的数据集提供了丰富的带有关键点或边界框标注的人体姿态样本。由于其来源为真实照片，所呈现的人类形象自然无异常肢体表现。

其次，另一类数据集专注于人工场景下人形图像的表现，如绘画、卡通或其他模拟环境。其中，Human-Art数据集\cite{ju2023humanART}收录了50,000张以人类为主体的图像，涵盖了五个自然场景和十五个不同的人工场景，并配以详尽的姿态和文本注解。不过，无论是此类真实照片数据集还是人工场景数据集，均未提供大规模合成图像或关于肢体异常的标注信息。

另外，现有的大型图像生成所需数据集在面对人类图像生成任务时普遍存在以下缺陷：\textbf{1)} 图像质量和分辨率较低，如Market-1501\cite{zheng2015scalable}包含分辨率为$128 \times 64$的嘈杂行人图像，而VITON\cite{han2018viton}则有人体着装对，分辨率为$256 \times 192$，这样的分辨率对于训练高清晰度模型来说并不足够。\textbf{2)} 某些领域的多样性有限，比如SHHQ\cite{fu2022stylegan}主要由全身人物及干净背景组成，而DeepFashion\cite{liu2016deepfashion}则聚焦于时尚服饰图像，姿态变化较少。\textbf{3)} 数据规模不足，LIP\cite{gong2017look}和Human-Art\cite{ju2023human}数据集仅包含了约$50\mathrm{K}$个样本。

针对文本驱动的人类图像生成任务中所面临的肢体异常挑战，本文在此项研究中创建了一个名为AbHuman的新颖数据集。这个数据集作为一种宝贵的资源，专门用于有效应对根据文本描述生成人类图像时可能出现的肢体异常问题。

\input{docs/chap01_25}

\section{本文的论文结构与章节安排}

\label{sec:arrangement}

接下来，本文详细介绍本文的结构与章节安排：

\begin{itemize}
\item \textbf{第一章——绪论}：本章首先对当前研究课题所处的学术背景与现实需求进行了精炼概述，明确指出其在促进人工智能技术发展、丰富数字内容创作手段以及推动人机交互模式创新等方面的重要意义。接着，对文本到图像生成领域的研究脉络进行了系统梳理，特别关注近年来该领域在人体图像生成方向所取得的关键进展与技术革新。

  文献回顾部分，简明扼要地勾勒了从DDPM，到现代深度学习模型（如GANs、VAEs）在人体图像生成任务中的广泛应用。对于已有的代表性人体生成数据集（如DeepFashion、Laion、Human-Art等），简述其主要特点、数据规模及对相关研究的推动作用，同时也适度提及其在人体姿态多样性、异常标注精细度等方面的局限性，为后续章节介绍AbHuman数据集的创新之处埋下伏笔。

\item \textbf{第二章——相关技术概述}：本章旨在为读者提供对文本到图像生成核心技术的概览理解。首先，对扩散模型这一新兴技术的核心工作机制进行阐述，解析其通过逐步减少添加至图像的高斯噪声来逆向生成清晰图像的过程，强调其在生成多样性和图像质量方面的优势。

  针对扩散模型在人体图像生成任务的应用，重点讨论其如何通过条件信息整合、潜在空间扩散以及模型架构创新等方式，适应人体形态复杂性及场景互动性的要求。此外，探讨了如何利用预训练模型进行针对性微调，以满足特定任务需求，如异常检测与修复。

  对于在特定约束条件下进行图像生成的问题，本章简要介绍了现有技术路径，如参数高效调优等方法，以及如何利用强化学习、对抗学习等手段提高生成图像的细节控制精度、视觉一致性与真实感。

\item \textbf{第三章——AbHuman数据集}：本章详细介绍了原创性AbHuman数据集的构建过程与核心属性。首先概述数据收集策略，包括多元化数据源的选择、数据质量控制标准的设定以及伦理合规的考虑。然后，详细描述了利用前沿文本到图像生成模型（如扩散模型）生成大规模人体图像的具体步骤，包括文本描述模板设计、模型微调与后期优化等关键环节。

  在异常标注部分，介绍了异常类别定义、标注规范的制定以及采用自动化与人工复核相结合的方式确保标注准确性的流程。最后，通过一系列数据集统计分析，如人体姿态分布、异常类别占比等，直观展现了AbHuman数据集在规模、多样性、异常覆盖率等方面的特色与优势，为验证与评估HumanRefiner算法提供有力支持。

\item \textbf{第四章——HumanRefiner算法}：本章详细介绍了本文提出的HumanRefiner算法，一种用于人体异常修正的创新方法。首先，概述算法的整体框架与设计思想，强调其结合全局结构调整与局部细节修复的粗到细处理策略。

  然后，对算法的主要组成模块进行简明阐述：（1）文本引导模块，说明如何提取文本指令的语义特征并将其融入修复过程；（2）结构重建模块，描述如何使用适当技术（姿势适配器）对异常人体进行合理化重构；（3）细节修复模块，简述如何借助特定方法（重绘扩散模型）进行像素级修复，恢复肢体结构等细节。

\item \textbf{第五章——实验结果与分析}：本章通过严谨的实验设计与数据分析，验证了HumanRefiner算法在AbHuman数据集上的性能。首先，通过与最新人体异常修正方法的定量对比（如FID分数、CLIP指标等），客观反映其在生成质量、异常纠正准确度等方面的表现。其次，提及进行了人工评估，邀请专家与用户对修正结果进行主观评价，以确认算法的实际效果与用户接受度。

  此外，本章还简述了算法对不同类型、不同程度异常的适应性，以及在不同文本指导下生成结果的一致性与多样性，初步评估其泛化能力和灵活性。最后，通过实例展示与简单错误分析，直观呈现算法在特定场景下的处理效果与潜在改进空间。

\item \textbf{第六章——结论与未来工作}：本章对全文研究成果进行了总结，提炼了HumanRefiner算法在人体异常修正任务中的创新点与技术价值，强调其对文本到图像生成领域，特别是人体图像修复研究的贡献。同时，基于现有工作面临的挑战与未来技术趋势，前瞻性地提出可能的研究方向，如增强文本指导的精准性与灵活性、开发轻量级模型与加速策略、结合3D技术提升生成真实感等。这些展望旨在为后续研究与技术发展提供启示，推动文本到图像生成技术在人体图像修复领域的持续进步。
\end{itemize}